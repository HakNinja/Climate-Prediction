{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 11055,
     "status": "error",
     "timestamp": 1715247037095,
     "user": {
      "displayName": "Deepak Kumar",
      "userId": "16659896723449052078"
     },
     "user_tz": -330
    },
    "id": "lE3tAUdMsAN6",
    "outputId": "403d3d13-69bf-4998-e21d-c29185804b28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakninja/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47831/2341479747.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mlstm_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mlstm_cv_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanual_cross_val_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mrmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6289\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6290\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6291\u001b[0m         ):\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Prepare data\n",
    "X = data.drop(columns=['date_time', 'maxtempC'])\n",
    "y = data['maxtempC']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function for manual cross-validation and RMSE calculation for Keras models\n",
    "def manual_cross_val_rmse(model, X, y, cv):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=150, batch_size=32, verbose=0)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_val_fold, y_pred)))\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# Initialize lists to store model names and RMSE scores\n",
    "models = []\n",
    "rmses = []\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr.predict(X_test)))\n",
    "lr_cv_rmse = np.mean(cross_val_score(lr, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Linear Regression')\n",
    "rmses.append(lr_rmse)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "lasso_cv_rmse = np.mean(cross_val_score(lasso, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Lasso')\n",
    "rmses.append(lasso_rmse)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge.predict(X_test)))\n",
    "ridge_cv_rmse = np.mean(cross_val_score(ridge, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Ridge')\n",
    "rmses.append(ridge_rmse)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_rmse = np.sqrt(mean_squared_error(y_test, svm.predict(X_test)))\n",
    "svm_cv_rmse = np.mean(cross_val_score(svm, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('SVM')\n",
    "rmses.append(svm_rmse)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "rf_cv_rmse = np.mean(cross_val_score(rf, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Random Forest')\n",
    "rmses.append(rf_rmse)\n",
    "\n",
    "# LSTM Model\n",
    "X_lstm = X.values.reshape((X.shape[0], 1, X.shape[1]))\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(1, X.shape[1])))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_model.predict(X_test.reshape((X_test.shape[0], 1, X_test.shape[1])))))\n",
    "lstm_cv_rmse = manual_cross_val_rmse(lstm_model, X_lstm, y.values, cv=5)\n",
    "models.append('LSTM')\n",
    "rmses.append(lstm_rmse)\n",
    "\n",
    "# GRU Model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(50, activation='relu', input_shape=(1, X.shape[1])))\n",
    "gru_model.add(Dense(1))\n",
    "gru_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "gru_rmse = np.sqrt(mean_squared_error(y_test, gru_model.predict(X_test.reshape((X_test.shape[0], 1, X_test.shape[1])))))\n",
    "gru_cv_rmse = manual_cross_val_rmse(gru_model, X_lstm, y.values, cv=5)\n",
    "models.append('GRU')\n",
    "rmses.append(gru_rmse)\n",
    "\n",
    "# CNN Model\n",
    "X_cnn = X.values.reshape((X.shape[0], X.shape[1], 1))\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "cnn_rmse = np.sqrt(mean_squared_error(y_test, cnn_model.predict(X_test.reshape((X_test.shape[0], X_test.shape[1], 1)))))\n",
    "cnn_cv_rmse = manual_cross_val_rmse(cnn_model, X_cnn, y.values, cv=5)\n",
    "models.append('CNN')\n",
    "rmses.append(cnn_rmse)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results = pd.DataFrame({'Model': models, 'RMSE': rmses, 'Cross-Validation RMSE': [lr_cv_rmse, lasso_cv_rmse, ridge_cv_rmse, svm_cv_rmse, rf_cv_rmse, lstm_cv_rmse, gru_cv_rmse, cnn_cv_rmse]})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results)\n",
    "\n",
    "# RMSE Comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, rmses, color='skyblue', label='Test RMSE')\n",
    "plt.bar(models, results['Cross-Validation RMSE'], color='orange', label='Cross-Validation RMSE')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Prepare data\n",
    "X = data.drop(columns=['date_time', 'maxtempC'])\n",
    "y = data['maxtempC']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function for manual cross-validation and RMSE calculation for Keras models\n",
    "def manual_cross_val_rmse(model, X, y, cv):\n",
    "  kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "  rmse_scores = []\n",
    "  for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=150, batch_size=32, verbose=0)\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    rmse_scores.append(np.sqrt(mean_squared_error(y_val_fold, y_pred)))\n",
    "  return np.mean(rmse_scores)\n",
    "\n",
    "# Initialize lists to store model names and RMSE scores\n",
    "models = []\n",
    "rmses = []\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr.predict(X_test)))\n",
    "lr_cv_rmse = np.mean(cross_val_score(lr, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Linear Regression')\n",
    "rmses.append(lr_rmse)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "lasso_cv_rmse = np.mean(cross_val_score(lasso, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Lasso')\n",
    "rmses.append(lasso_rmse)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge.predict(X_test)))\n",
    "ridge_cv_rmse = np.mean(cross_val_score(ridge, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Ridge')\n",
    "rmses.append(ridge_rmse)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_rmse = np.sqrt(mean_squared_error(y_test, svm.predict(X_test)))\n",
    "svm_cv_rmse = np.mean(cross_val_score(svm, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('SVM')\n",
    "rmses.append(svm_rmse)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "rf_cv_rmse = np.mean(cross_val_score(rf, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "models.append('Random Forest')\n",
    "rmses.append(rf_rmse)\n",
    "\n",
    "# LSTM Model\n",
    "X_lstm = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))  # Reshape training data\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(1, X.shape[1])))  # Use X.shape[1] here\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.fit(X_lstm, y_train, epochs=150, batch_size=32, verbose=0)  # Train with reshaped data\n",
    "\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_model.predict(X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1])))))\n",
    "lstm_cv_rmse = manual_cross_val_rmse(lstm_model, X_lstm, y.values, cv=5)  # Use reshaped data for cross-validation\n",
    "models.append('LSTM')\n",
    "rmses.append(lstm_rmse)\n",
    "\n",
    "# GRU Model (similar to LSTM)\n",
    "X_gru = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(50, activation='relu', input_shape=(1, X.shape[1])))\n",
    "gru_model.add(Dense(1))\n",
    "gru_model.compile(optimizer='adam', loss='mse')\n",
    "gru_model.fit(X_gru, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "\n",
    "gru_rmse = np.sqrt(mean_squared_error(y_test, gru_model.predict(X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1])))))\n",
    "gru_cv_rmse = manual_cross_val_rmse(gru_model, X_gru, y.values, cv=5)\n",
    "\n",
    "\n",
    "models.append('GRU')\n",
    "rmses.append(gru_rmse)\n",
    "\n",
    "# CNN Model\n",
    "X_cnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))  # Reshape training data\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(50, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "cnn_model.compile(optimizer='adam', loss='mse')\n",
    "cnn_model.fit(X_cnn, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "\n",
    "cnn_rmse = np.sqrt(mean_squared_error(y_test, cnn_model.predict(X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1)))))\n",
    "cnn_cv_rmse = manual_cross_val_rmse(cnn_model, X_cnn, y.values, cv=5)\n",
    "models.append('CNN')\n",
    "rmses.append(cnn_rmse)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results = pd.DataFrame({'Model': models, 'RMSE': rmses, 'Cross-Validation RMSE': [lr_cv_rmse, lasso_cv_rmse, ridge_cv_rmse, svm_cv_rmse, rf_cv_rmse, lstm_cv_rmse, gru_cv_rmse, cnn_cv_rmse]})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results)\n",
    "\n",
    "# RMSE Comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, rmses, color='skyblue', label='Test RMSE')\n",
    "plt.bar(models, results['Cross-Validation RMSE'], color='orange', label='Cross-Validation RMSE')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPzCsBOzaOF14iUk4uMpavp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
